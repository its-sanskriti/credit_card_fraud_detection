ğŸ§  Project Overview

This project demonstrates the end-to-end data preprocessing pipeline â€” from handling missing values and scaling to feature transformation and model evaluation â€” using the Credit Card Fraud Detection Dataset.
Itâ€™s designed as a learning guide for anyone diving deep into data preprocessing, emphasizing how data quality impacts model performance.

ğŸ“‚ Dataset

Source: Kaggle - Credit Card Fraud Detection

Shape: 284,807 rows Ã— 31 columns

Features V1â€“V28 are PCA-transformed components

Amount represents transaction value

Class is the target (0 â†’ Genuine, 1 â†’ Fraud)

1ï¸âƒ£ Data Loading & Initial Exploration

Loaded dataset using Pandas

Checked shape, data types, and null values

No missing values found âœ…
2ï¸âƒ£ Data Imbalance Analysis

Verified class distribution (fraud vs. genuine)

Severe imbalance observed: Fraud â‰ˆ 0.17% of total transactions

Used SMOTE later to synthetically balance classes

3ï¸âƒ£ Outlier & Distribution Analysis

Visualized Amount column using boxplots and histograms

Identified heavy right-skew â†’ opted for log transformation

4ï¸âƒ£ Transformation

Applied log transformation to Amount

Resulted in near-Gaussian distribution

Confirmed via describe() summary and visualization

ğŸ“ 5ï¸âƒ£ Feature Scaling

Used StandardScaler for normalized Gaussian-like data

Resulting Amount_scaled feature:

Mean â‰ˆ 0

Std â‰ˆ 1

Gaussian-shaped distribution âœ…

ğŸ§© 6ï¸âƒ£ Splitting Dataset

Split into X_train, X_test, y_train, y_test (80:20 ratio)

Used stratify=y to maintain class ratio

ğŸ§  7ï¸âƒ£ Model Training (Baseline)

Trained Logistic Regression on SMOTE-balanced data

Tuned max_iter=1000 to avoid convergence warning

Evaluated with accuracy, recall, F1, and ROC-AUC metrics

ğŸ“Š 8ï¸âƒ£ Model Evaluation

Confusion Matrix:

True Negatives: âœ… 56,267

False Positives: âš ï¸ 597

False Negatives: âŒ 9

True Positives: âœ…89
Metrics Summary:

Metric	Score
Accuracy	0.99
Recall (Fraud)	0.91
ROC-AUC	0.97
9ï¸âƒ£ Precisionâ€“Recall & ROC Curves

Visualized Confusion Matrix, ROC Curve, and Precision-Recall Curve

PR curve offers clearer insights for imbalanced data

Observed strong recall with moderate precision â€” ideal tradeoff for fraud detection
